{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:49:23.184885Z",
     "start_time": "2018-07-01T19:49:23.178066Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:49:23.565086Z",
     "start_time": "2018-07-01T19:49:23.543795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.,   2.,   3.,   4.],\n",
      "        [  5.,   6.,   7.,   8.],\n",
      "        [  9.,  10.,  11.,  12.]]) <- tensor\n",
      "\n",
      "torch.Size([3, 4]) <- tensor size\n",
      "\n",
      "3 <- dimension size\n",
      "\n",
      "tensor([[  6.,   7.],\n",
      "        [ 10.,  11.]]) <- slicing support\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Создаем тензор\n",
    "x = torch.rand([3, 4])\n",
    "x = torch.zeros([3, 4])\n",
    "x = torch.ones([3, 4, 3])\n",
    "\n",
    "# print x\n",
    "#x = torch.eye(3, 4)\n",
    "\n",
    "x = torch.Tensor(\n",
    "[[1,  2,  3,  4],\n",
    " [5,  6,  7,  8],\n",
    " [9, 10, 11, 12]])\n",
    "\n",
    "print(x, '<- tensor\\n')\n",
    "print(x.size(), '<- tensor size\\n')\n",
    "print(x.size(0), '<- dimension size\\n')\n",
    "print(x[1:, 1:3], '<- slicing support\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:50:09.548172Z",
     "start_time": "2018-07-01T19:50:09.533465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.,   2.,   3.,   4.],\n",
      "        [  1.,   1.,   1.,   1.],\n",
      "        [  9.,  10.,  11.,  12.]]) \n",
      " tensor([[  1.,   2.,   3.,   4.],\n",
      "        [  1.,   1.,   1.,   1.],\n",
      "        [  9.,  10.,  11.,  12.]]) <- shallow copy\n",
      "\n",
      "tensor([[  1.,   2.,   3.,   4.],\n",
      "        [  1.,   1.,   1.,   1.],\n",
      "        [  9.,  10.,  11.,  12.]]) \n",
      " tensor([[  1.,   2.,   3.,   4.],\n",
      "        [  2.,   2.,   2.,   2.],\n",
      "        [  9.,  10.,  11.,  12.]]) <- deep copy\n"
     ]
    }
   ],
   "source": [
    "# Копирование (по ссылке и глубокое)\n",
    "y = x\n",
    "\n",
    "y[1, :] = 1\n",
    "print(x, '\\n', y, '<- shallow copy\\n')\n",
    "\n",
    "y = x.clone()\n",
    "y[1, :] = 2\n",
    "print(x, '\\n', y, '<- deep copy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:50:55.156964Z",
     "start_time": "2018-07-01T19:50:55.142559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2.,   4.,   6.,   8.],\n",
      "        [  3.,   3.,   3.,   3.],\n",
      "        [ 18.,  20.,  22.,  24.]]) tensor([[   1.,    4.,    9.,   16.],\n",
      "        [   2.,    2.,    2.,    2.],\n",
      "        [  81.,  100.,  121.,  144.]]) tensor([[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.5000,  0.5000,  0.5000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000]]) tensor([[ 0.,  0.,  0.,  0.],\n",
      "        [-1., -1., -1., -1.],\n",
      "        [ 0.,  0.,  0.,  0.]])\n",
      "tensor([[ 0.,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1.,  1.],\n",
      "        [ 0.,  0.,  0.,  0.]]) tensor([[   1.,    4.,    9.,   16.],\n",
      "        [   1.,    1.,    1.,    1.],\n",
      "        [  81.,  100.,  121.,  144.]]) tensor([[ 1.0000e+00,  4.0000e+00,  2.7000e+01,  2.5600e+02],\n",
      "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
      "        [ 3.8742e+08,  1.0000e+10,  2.8531e+11,  8.9161e+12]]) <- basic math\n"
     ]
    }
   ],
   "source": [
    "# Математические операции (стандартные поэлементные)\n",
    "print(x + y, x * y, x / y, x - y,)\n",
    "print(x % y, x**2, x**y, '<- basic math')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:50:55.324289Z",
     "start_time": "2018-07-01T19:50:55.311976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.7183e+00,  7.3891e+00,  2.0086e+01,  5.4598e+01],\n",
      "        [ 2.7183e+00,  2.7183e+00,  2.7183e+00,  2.7183e+00],\n",
      "        [ 8.1031e+03,  2.2026e+04,  5.9874e+04,  1.6275e+05]])\n",
      "tensor([[ 0.0000,  0.6931,  1.0986,  1.3863],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 2.1972,  2.3026,  2.3979,  2.4849]])\n",
      "tensor([[ 0.8415,  0.9093,  0.1411, -0.7568],\n",
      "        [ 0.8415,  0.8415,  0.8415,  0.8415],\n",
      "        [ 0.4121, -0.5440, -1.0000, -0.5366]])\n"
     ]
    }
   ],
   "source": [
    "# Более сложные операции\n",
    "print(torch.exp(x))\n",
    "print(torch.log(x))\n",
    "print(torch.sin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  1],\n",
       "        [ 0,  0,  0,  0],\n",
       "        [ 1,  1,  1,  1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:50:55.451918Z",
     "start_time": "2018-07-01T19:50:55.439867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  4.,   9.,  10.,  11.,  12.])\n",
      "tensor([[ 0,  0,  0,  1],\n",
      "        [ 0,  0,  0,  0],\n",
      "        [ 1,  1,  1,  1]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# Логические операции\n",
    "y = x[x > 3]\n",
    "print(y)\n",
    "y = (x > 3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:50:55.883799Z",
     "start_time": "2018-07-01T19:50:55.869374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.,   2.,   3.,   4.],\n",
      "        [  1.,   1.,   1.,   1.],\n",
      "        [  9.,  10.,  11.,  12.]])\n",
      "tensor([[  1.,   2.,   3.,   4.],\n",
      "        [  1.,   1.,   1.,   1.],\n",
      "        [  9.,  10.,  11.,  12.]], dtype=torch.float64)\n",
      "tensor([[  1,   2,   3,   4],\n",
      "        [  1,   1,   1,   1],\n",
      "        [  9,  10,  11,  12]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Переопределение типа\n",
    "x = x.float()\n",
    "print(x)\n",
    "x = x.double()\n",
    "print(x)\n",
    "x = x.int()\n",
    "print(x)\n",
    "x = x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:50:56.556514Z",
     "start_time": "2018-07-01T19:50:56.537230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [4 3 2 1]]\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 4,  3,  2,  1]])\n",
      "[[1 2 3 4]\n",
      " [4 3 2 1]]\n",
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 4.,  3.,  2.,  1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Взаимодействие с Numpy\n",
    "x = numpy.array([[1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "print(x)\n",
    "x = torch.from_numpy(x)\n",
    "print(x)\n",
    "x = x.numpy()\n",
    "print(x)\n",
    "x = torch.from_numpy(x).float().int().double()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T20:46:30.246398Z",
     "start_time": "2018-07-01T20:46:30.239804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is avaliable\n",
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 4.,  3.,  2.,  1.]], dtype=torch.float64, device='cuda:0') <- CUDA Tensor!\n",
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 4.,  3.,  2.,  1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Перемещение на GPU\n",
    "import time\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device, 'is avaliable')\n",
    "x_cuda = x.to('cuda:0')\n",
    "#x_cuda = x.to(device)\n",
    "print(x_cuda, '<- CUDA Tensor!')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/teacher/AI Boot Camp/deep_learning_course_2.0\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul  3 12:45:21 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 107...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "|  0%   47C    P8     7W / 180W |    767MiB /  8105MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0       985      G   /usr/lib/xorg/Xorg                           166MiB |\r\n",
      "|    0      1737      G   compiz                                       119MiB |\r\n",
      "|    0     20476      C   /usr/bin/python3                             469MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cuda = x.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T20:45:50.719046Z",
     "start_time": "2018-07-01T20:45:50.711778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.2 µs ± 48.4 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# CPU time\n",
    "%timeit y = (x - x + x*10.0) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T20:46:33.594104Z",
     "start_time": "2018-07-01T20:46:33.590407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.1 µs ± 98.6 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# GPU time\n",
    "%timeit y_cuda = (x_cuda - x_cuda + x_cuda * 10.0) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cuda.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T20:03:38.164937Z",
     "start_time": "2018-07-01T20:03:38.154058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(650)\n",
      "tensor([[  2,   4,   6,   8],\n",
      "        [ 10,  12,  14,  16],\n",
      "        [ 18,  20,  22,  24]]) <- gradient\n"
     ]
    }
   ],
   "source": [
    "# Автоматическое (символьное) дифференциирование (обратное распространение градиента) (случай скаляра)\n",
    "import torch.autograd\n",
    "\n",
    "x = torch.tensor(\n",
    "    [[1,  2,  3,  4],\n",
    "     [5,  6,  7,  8],\n",
    "     [9, 10, 11, 12]], requires_grad=True)\n",
    "\n",
    "formula = (x ** 2).sum().median()\n",
    "print(formula)\n",
    "formula.backward()\n",
    "\n",
    "print(x.grad, '<- gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T20:30:40.079846Z",
     "start_time": "2018-07-01T20:30:40.069890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MedianBackward0 object at 0x7efc97230ef0>\n",
      "<SumBackward0 object at 0x7efc97230eb8>\n",
      "<PowBackward0 object at 0x7efc97230ef0>\n",
      "<AccumulateGrad object at 0x7efc97230f28>\n"
     ]
    }
   ],
   "source": [
    "# Как тензор хранит свою историю\n",
    "print(formula.grad_fn)\n",
    "print(formula.grad_fn.next_functions[0][0])\n",
    "print(formula.grad_fn.next_functions[0][0].next_functions[0][0])\n",
    "print(formula.grad_fn.next_functions[0][0].next_functions[0][0].next_functions[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "Написать и вычислить бинарную кросс-энтопию для векторов target и probs при помощи средств pytorch.\n",
    "Бинарная кросс-энтропия вычисляется:\n",
    "\n",
    "$$BCE(t, p) = - \\sum_i t_i \\log(p_i) + (1 - t_i) \\log(1 - p_i)$$\n",
    "\n",
    "target = (0, 0, 0, 0, 1, 1, 1, 1)\n",
    "probs = (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8)\n",
    "\n",
    "Какой из элементов суммы дает наибольший вклад в функцию потерь?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = (0, 0, 0, 0, 1, 1, 1, 1)\n",
    "probs = (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8)\n",
    "BCE = 0\n",
    "for number in [0, 1, 2, 3, 4, 5, 6, 7]:\n",
    "    BCE = BCE - target[i]*log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([0, 0, 0, 0, 1, 1, 1, 1]).float()\n",
    "p = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCE(t,p):\n",
    "    BCE= -(t*torch.log(p)+(1-t)*torch.log(1-p)).sum()\n",
    "    return (BCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9798)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BCE(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-t*torch.log(p)-(1-t)*torch.log(1-p)).argmax()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.nn.CrossEntropyLoss\n",
    "import torch.functional as F\n",
    "F.CrossEntropyLoss(t,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2\n",
    "\n",
    "Логистическая регрессия минимизирует функцию бинарной кросс-энтропии (BCE), предполагая, что\n",
    "$$p_i = \\sigma (< w_i, x_i >)$$\n",
    "где $w_i$ -- веса свойств объектов, $x_i$ -- свойства объектов. Пусть $\\vec{x} = (1, x_1, x_2)$. Подставить вероятности в выражение $BCE$ и найти производную $BCE$ по весам.\n",
    "Вычислить производную в случае двух объектов (любым способом, можно посчитать руками, можно написать скрипт):\n",
    "\n",
    "$t = 1, x = (1, 1, 1)$\n",
    "\n",
    "$t = 0, x = (1, 0, 1)$\n",
    "\n",
    "В точке w = (0, 0, 0).\n",
    "\n",
    "Совпадает ли результат явного вычисления с результатом работы функции backward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_2 = torch.tensor([1, 0], requires_grad=True, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def sigma(x_1,x_2):\n",
    "    sigma = torch.Tensor( (1 / (1 + torch.exp(x_1)), 1 / (1 + torch.exp(x_1)) ) )\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor([[1,  1,  1]], dtype = torch.float32)\n",
    "torch.log(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3863)\n",
      "None None <- gradient\n"
     ]
    }
   ],
   "source": [
    "import torch.autograd\n",
    "\n",
    "x_1 = torch.tensor(\n",
    "    [1,  1,  1], requires_grad=True, dtype = torch.float32)\n",
    "x_2 = torch.tensor(\n",
    "    [1,  0,  1], requires_grad=True, dtype = torch.float32)\n",
    "w = torch.tensor(\n",
    "    [0,  0,  0], requires_grad=True, dtype = torch.float32)\n",
    "\n",
    "formula = BCE(t_2, sigma((x_1 * w).sum(),(x_2 * w).sum()))\n",
    "print(formula)\n",
    "formula.backward()\n",
    "\n",
    "print(x_1.grad, x_2.grad, '<- gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mul() received an invalid combination of arguments - got (builtin_function_or_method), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (!builtin_function_or_method!)\n * (float other)\n      didn't match because some of the arguments have invalid types: (!builtin_function_or_method!)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-c96da1879f3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     [0,  0,  0], requires_grad=True)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mformula\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-170-0866d251032f>\u001b[0m in \u001b[0;36mBCE\u001b[0;34m(t, p)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mBCE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mBCE\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: mul() received an invalid combination of arguments - got (builtin_function_or_method), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (!builtin_function_or_method!)\n * (float other)\n      didn't match because some of the arguments have invalid types: (!builtin_function_or_method!)\n"
     ]
    }
   ],
   "source": [
    "import torch.autograd\n",
    "\n",
    "x_1 = torch.tensor(\n",
    "    [1,  1,  1], requires_grad=True, dtype = torch.float32)\n",
    "x_2 = torch.tensor(\n",
    "    [1,  0,  1], requires_grad=True, dtype = torch.float32)\n",
    "w = torch.tensor(\n",
    "    [0,  0,  0], requires_grad=True, dtype = torch.float32)\n",
    "\n",
    "formula = BCE(t_2, sigma((x_1 * w).sum(),(x_2 * w).sum()))\n",
    "print(formula)\n",
    "formula.backward()\n",
    "\n",
    "print(x_1.grad, x_2.grad, '<- gradient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "\n",
    "Средствами pytorch реализовать алгоритм градиентного спуска.\n",
    "\n",
    "При помощи этого алгоритма найти минимум функций:\n",
    "$x^2 + y^2$ с начальным приближением $x_0 = 10, y_0 = 5$, \n",
    "\n",
    "$0.5 \\log x + 0.5 \\log (1 - x)$ с начальным приближением $x_0 = 0.9$, \n",
    "\n",
    "$x^2 + 10 y^2 + 2xy$, с начальным приближением $x_0 = 10.0, y_0 = 10.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4\n",
    "\n",
    "\n",
    "При помощи алгоритма градиентного спуска оптимизировать вектор probs при фиксированном векторе target из задания 1.\n",
    "Рассмотреть два варианта решения задачи: \n",
    "\n",
    "1) при помощи CPU \n",
    "\n",
    "2) при помощи GPU\n",
    "\n",
    "Получилось ли ускорить процесс при помощи GPU? Обсудить, почему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "О градиентном спуске:\n",
    "https://ru.wikipedia.org/wiki/%D0%93%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D1%83%D1%81%D0%BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
